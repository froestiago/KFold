{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.6 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "e195ad74c1f1f25b431fdad758182e5c1b96f087f382f48f0b05b5503f70a0ae"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importa modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "digits = load_digits()\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast_cancer = load_breast_cancer()\n",
    "\n",
    "#escolhe dataset\n",
    "dt = breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estes metodos servem para matrizes não binárias\n",
    "#A fazer: um metodo que dado um elemento da matriz, transforma o \"resto\" da matriz toda em uma matriz binaria para melhor fazer a analise\n",
    "def accuracy(matrix):\n",
    "    trace = matrix.trace()\n",
    "    total_sum = matrix.sum()\n",
    "    accuracy = trace/total_sum\n",
    "    return accuracy\n",
    "\n",
    "def recall(matrix, element_index):\n",
    "    return matrix[element_index][element_index]/matrix[element_index].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stratifiedKFold = KFold que conserva a % de cada classe nos folds\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "folds = StratifiedKFold(n_splits=5)\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "metrics_dict = {'Train Index' : [],\n",
    "                'Test Index' : [],\n",
    "                'Confusion Matrix' : [],\n",
    "                'Accuracy' : [],\n",
    "                'Error' : [],\n",
    "                'Recall' : [],\n",
    "                'Precision' : [],\n",
    "                'MCC' : [],\n",
    "                'F1' : [],\n",
    "                'Kappa' : [],\n",
    "                'ROC AUC' : []}\n",
    "\n",
    "for train_index, test_index in folds.split(dt.data,dt.target):\n",
    "    X_train, X_test, y_train, y_test = dt.data[train_index], dt.data[test_index], \\\n",
    "                                       dt.target[train_index], dt.target[test_index]\n",
    "    \n",
    "    metrics_dict['Train Index'].append(train_index)\n",
    "    metrics_dict['Test Index'].append(test_index)\n",
    "    \n",
    "    #Logistic Regression\n",
    "    logistic_model = LogisticRegression(solver='liblinear',multi_class='ovr')\n",
    "    logistic_model.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logistic_model.predict(X_test)\n",
    "    y_pred_logistic.append(y_pred)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    metrics_dict['Confusion Matrix'].append(cm)\n",
    "\n",
    "    metrics_dict['Accuracy'].append(metrics.accuracy_score(y_test, y_pred))\n",
    "    metrics_dict['Error'].append(1-acc)\n",
    "    metrics_dict['Recall'].append(metrics.recall_score(y_test, y_pred)) #sensibilidade\n",
    "    metrics_dict['Precision'].append(metrics.precision_score(y_test, y_pred)) \n",
    "    metrics_dict['MCC'].append(metrics.matthews_corrcoef(y_test, y_pred))\n",
    "    metrics_dict['F1'].append(metrics.f1_score(y_test, y_pred))\n",
    "    metrics_dict['Kappa'].append(metrics.cohen_kappa_score(y_test, y_pred))\n",
    "    metrics_dict['ROC AUC'].append(metrics.roc_auc_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                         Train Index  \\\n",
       "0  [53, 54, 56, 57, 62, 64, 65, 70, 72, 73, 75, 7...   \n",
       "1  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "2  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "3  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "4  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...   \n",
       "\n",
       "                                          Test Index    Confusion Matrix  \\\n",
       "0  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...  [[36, 7], [1, 70]]   \n",
       "1  [53, 54, 56, 57, 62, 64, 65, 70, 72, 73, 75, 7...  [[38, 5], [2, 69]]   \n",
       "2  [164, 167, 168, 171, 172, 177, 180, 181, 182, ...  [[40, 2], [1, 71]]   \n",
       "3  [255, 256, 257, 258, 259, 260, 261, 262, 263, ...  [[39, 3], [3, 69]]   \n",
       "4  [389, 392, 393, 400, 408, 414, 417, 430, 432, ...  [[41, 1], [3, 68]]   \n",
       "\n",
       "   Accuracy     Error    Recall  Precision       MCC        F1     Kappa  \\\n",
       "0  0.929825  0.035398  0.985915   0.909091  0.852085  0.945946  0.846413   \n",
       "1  0.938596  0.035398  0.971831   0.932432  0.868888  0.951724  0.867486   \n",
       "2  0.973684  0.035398  0.986111   0.972603  0.943340  0.979310  0.943170   \n",
       "3  0.947368  0.035398  0.958333   0.958333  0.886905  0.958333  0.886905   \n",
       "4  0.964602  0.035398  0.957746   0.985507  0.925594  0.971429  0.924942   \n",
       "\n",
       "    ROC AUC  \n",
       "0  0.911562  \n",
       "1  0.927776  \n",
       "2  0.969246  \n",
       "3  0.943452  \n",
       "4  0.966968  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Train Index</th>\n      <th>Test Index</th>\n      <th>Confusion Matrix</th>\n      <th>Accuracy</th>\n      <th>Error</th>\n      <th>Recall</th>\n      <th>Precision</th>\n      <th>MCC</th>\n      <th>F1</th>\n      <th>Kappa</th>\n      <th>ROC AUC</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[53, 54, 56, 57, 62, 64, 65, 70, 72, 73, 75, 7...</td>\n      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n      <td>[[36, 7], [1, 70]]</td>\n      <td>0.929825</td>\n      <td>0.035398</td>\n      <td>0.985915</td>\n      <td>0.909091</td>\n      <td>0.852085</td>\n      <td>0.945946</td>\n      <td>0.846413</td>\n      <td>0.911562</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n      <td>[53, 54, 56, 57, 62, 64, 65, 70, 72, 73, 75, 7...</td>\n      <td>[[38, 5], [2, 69]]</td>\n      <td>0.938596</td>\n      <td>0.035398</td>\n      <td>0.971831</td>\n      <td>0.932432</td>\n      <td>0.868888</td>\n      <td>0.951724</td>\n      <td>0.867486</td>\n      <td>0.927776</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n      <td>[164, 167, 168, 171, 172, 177, 180, 181, 182, ...</td>\n      <td>[[40, 2], [1, 71]]</td>\n      <td>0.973684</td>\n      <td>0.035398</td>\n      <td>0.986111</td>\n      <td>0.972603</td>\n      <td>0.943340</td>\n      <td>0.979310</td>\n      <td>0.943170</td>\n      <td>0.969246</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n      <td>[255, 256, 257, 258, 259, 260, 261, 262, 263, ...</td>\n      <td>[[39, 3], [3, 69]]</td>\n      <td>0.947368</td>\n      <td>0.035398</td>\n      <td>0.958333</td>\n      <td>0.958333</td>\n      <td>0.886905</td>\n      <td>0.958333</td>\n      <td>0.886905</td>\n      <td>0.943452</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13,...</td>\n      <td>[389, 392, 393, 400, 408, 414, 417, 430, 432, ...</td>\n      <td>[[41, 1], [3, 68]]</td>\n      <td>0.964602</td>\n      <td>0.035398</td>\n      <td>0.957746</td>\n      <td>0.985507</td>\n      <td>0.925594</td>\n      <td>0.971429</td>\n      <td>0.924942</td>\n      <td>0.966968</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "source": [
    "#Transformando o dicionário em um pandas dataframe e depois exportando como .csv\n",
    "dataframe = pd.DataFrame.from_dict(metrics_dict)\n",
    "dataframe.to_csv('metrics.csv', float_format='%.10f')\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}